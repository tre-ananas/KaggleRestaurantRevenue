step_corr(all_numeric_predictors(), threshold = 0.85) %>%
# PCR Threshold = .90
step_pca(all_numeric_predictors(), threshold = .85)
# Prep, Bake, and View Recipe
prepped <- prep(rec)
# Create Recipe
rec <- recipe(revenue ~ ., data = full_train) %>%
# Remove ID
step_rm(Id) %>%
# Create a date column with proper format
step_mutate(
Open_Date = as.Date(`Open Date`, format = "%m/%d/%Y")
) %>%
# Remove old date column
step_rm(`Open Date`) %>%
# Break down date into more specific features
step_date(Open_Date, features = c('month', 'quarter')) %>%
# Extract Season
step_mutate(season = factor(case_when(
between(month(Open_Date), 3, 5) ~ "Spring",
between(month(Open_Date), 6, 8) ~ "Summer",
between(month(Open_Date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
)))  %>%
# Remove Open_Date now that we have better features
step_rm(Open_Date) %>%
# Remove city names because there are new cities in the test data
step_rm(City) %>%
# Integers to factors
step_mutate_at(all_integer_predictors(), fn = factor) %>%
# Ignoring P-variables, turn appropriate variables into factors
step_mutate_at(c('City Group', 'Type'), fn = factor) %>%
# Target encode factors
step_dummy(all_nominal_predictors()) %>%
# Normalize numeric features
step_normalize(all_numeric_predictors()) %>%
# Remove zero-variance variables
step_zv()%>%
# Remove correlated features
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
# PCR Threshold = .90
step_pca(all_numeric_predictors(), threshold = .85)
# Prep, Bake, and View Recipe
prepped <- prep(rec)
baked <- bake(prepped, full_train) %>%
slice(1:10)
baked
# Set up model
linear_regression <- linear_reg() %>% # Type of model
set_engine("lm")# Engine = What R function to use--linear model here
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(linear_regression) %>%
fit(data = full_train) # Fit the workflow
# Look at fitted LM model
extract_fit_engine(wf) %>%
tidy()
##### Predictions
predict(wf, new_data = full_test)
full_test
summary(full_test$Type)
table(full_test$Type)
table(full_test$Train)
table(full_test$Type)
table(full_train$Type)
# Packages
library(vroom) # Loading Data
library(tidymodels) # Modeling and cross validation
library(tidyverse) # Everything, really
library(DataExplorer) # EDA
library(patchwork) # Plots
library(GGally) # EDA
library(naivebayes) # Naive Bayes
library(discrim) # PCR
library(lubridate) # Dates
library(embed) # Extra recipe steps
library(workflows) # Workflows
n# Data
train <- vroom('train.csv')
test <- vroom('test.csv')
turkey <- vroom('turkey.csv')
########## Clean and Merge
# Assuming your data frame is named 'turkey'
turkey <- turkey %>%
# Remove redundant columns
select(-latitude, -longitude, -`plate code`) %>%
# Change column name 'city' to 'City'
rename(City = city) %>%
# Remove dots in 'population' column and convert to numeric
mutate(population = as.numeric(gsub("\\.", "", population))) %>%
# Format 'per capita annual income' column
rename(`per capita annual income` = "
per capita annual income") %>%
mutate(`per capita annual income` = as.numeric(gsub(" TL", "", gsub("\\.", "", `per capita annual income`)))) %>%
# Format 'number of people with higher education and above' column
rename(`percentage w higher ed or more` = "number of people with higher education and above") %>%
mutate(`percentage w higher ed or more` = as.numeric(gsub("%", "", `percentage w higher ed or more`)))
# Merge turkey dataset with training and testing data
full_train <- merge(train, turkey, by = "City", all.x = TRUE)
full_test <- merge(test, turkey, by = "City", all.x = TRUE)
########## EDA
##### Variable Types
# Create Datasets for EDA
eda_train <- full_train
eda_test <- full_test
# Check Types
glimpse(eda_train)
glimpse(eda_test)
### Findings:
# `Open Date` > date
# City > factor
# `City Group` > factor
# Type > factor
# Many of the Ps > factor
# Change Types for Non-P Features
eda_train$`Open Date` <- as.Date(eda_train$`Open Date`, format = "%m/%d/%Y")
eda_train$City <- as.factor(eda_train$City)
eda_train$`City Group` <- as.factor(eda_train$`City Group`)
eda_train$Type <- as.factor(eda_train$Type)
eda_test$`Open Date` <- as.Date(eda_test$`Open Date`, format = "%m/%d/%Y")
eda_test$City <- as.factor(eda_test$City)
eda_test$`City Group` <- as.factor(eda_test$`City Group`)
eda_test$Type <- as.factor(eda_test$Type)
# Visualize Types
plot_intro(eda_train)
plot_intro(eda_test)
skimr::skim(eda)
skimr::skim(eda_train)
skimr::skim(eda_test)
# Subset 'full_test' to include only rows with missing data in some column
full_test[!complete.cases(full_test), ]
# Subset 'full_test' to include only rows with missing data in some column
incomplete_full_test <- full_test[!complete.cases(full_test), ]
incomplete_full_test
View(incomplete_full_test)
View(full_train)
View(full_test)
View(full_test)
View(full_train)
# Set up model
penalized_linear_regression <- linear_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(penalized_linear_regression) %>%
fit(data = full_train) # Fit the workflow
rec <- recipe(revenue ~ ., data = full_train) %>%
# Remove ID; Remove Type because EDA showed some problems
step_rm(Id, Type) %>%
# Create a date column with proper format
step_mutate(
Open_Date = as.Date(`Open Date`, format = "%m/%d/%Y")
) %>%
# Remove old date column
step_rm(`Open Date`) %>%
# Break down date into more specific features
step_date(Open_Date, features = c('month', 'quarter')) %>%
# Extract Season
step_mutate(season = factor(case_when(
between(month(Open_Date), 3, 5) ~ "Spring",
between(month(Open_Date), 6, 8) ~ "Summer",
between(month(Open_Date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
)))  %>%
# Remove Open_Date now that we have better features
step_rm(Open_Date) %>%
# Remove city names because there are new cities in the test data
step_rm(City) %>%
# Integers to factors
step_mutate_at(all_integer_predictors(), fn = factor) %>%
# Ignoring P-variables, turn appropriate variables into factors
step_mutate_at(c('City Group'), fn = factor) %>%
# Target encode factors
lencode_mixed(all_nominal_predictors(), outcome=vars(revenue)) %>%
# Median imputation for missing quantitative values
step_impute_median(population) %>%
step_impute_median(`per capita annual income`) %>%
step_impute_median(`percentage w higher ed or more`) %>%
# Normalize numeric features
step_normalize(all_numeric_predictors()) %>%
# Remove zero-variance variables
step_zv()%>%
# Remove correlated features
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
# PCR Threshold = .90
step_pca(all_numeric_predictors(), threshold = .85)
library(embed)
library(vroom) # Loading Data
library(tidymodels) # Modeling and cross validation
library(tidyverse) # Everything, really
library(DataExplorer) # EDA
library(patchwork) # Plots
library(GGally) # EDA
library(naivebayes) # Naive Bayes
library(discrim) # PCR
library(lubridate) # Dates
library(embed) # Extra recipe steps
library(workflows) # Workflows
# Create Recipe
rec <- recipe(revenue ~ ., data = full_train) %>%
# Remove ID; Remove Type because EDA showed some problems
step_rm(Id, Type) %>%
# Create a date column with proper format
step_mutate(
Open_Date = as.Date(`Open Date`, format = "%m/%d/%Y")
) %>%
# Remove old date column
step_rm(`Open Date`) %>%
# Break down date into more specific features
step_date(Open_Date, features = c('month', 'quarter')) %>%
# Extract Season
step_mutate(season = factor(case_when(
between(month(Open_Date), 3, 5) ~ "Spring",
between(month(Open_Date), 6, 8) ~ "Summer",
between(month(Open_Date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
)))  %>%
# Remove Open_Date now that we have better features
step_rm(Open_Date) %>%
# Remove city names because there are new cities in the test data
step_rm(City) %>%
# Integers to factors
step_mutate_at(all_integer_predictors(), fn = factor) %>%
# Ignoring P-variables, turn appropriate variables into factors
step_mutate_at(c('City Group'), fn = factor) %>%
# Target encode factors
lencode_mixed(all_nominal_predictors(), outcome=vars(revenue)) %>%
# Median imputation for missing quantitative values
step_impute_median(population) %>%
step_impute_median(`per capita annual income`) %>%
step_impute_median(`percentage w higher ed or more`) %>%
# Normalize numeric features
step_normalize(all_numeric_predictors()) %>%
# Remove zero-variance variables
step_zv()%>%
# Remove correlated features
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
# PCR Threshold = .90
step_pca(all_numeric_predictors(), threshold = .85)
# Create Recipe
rec <- recipe(revenue ~ ., data = full_train) %>%
# Remove ID; Remove Type because EDA showed some problems
step_rm(Id, Type) %>%
# Create a date column with proper format
step_mutate(
Open_Date = as.Date(`Open Date`, format = "%m/%d/%Y")
) %>%
# Remove old date column
step_rm(`Open Date`) %>%
# Break down date into more specific features
step_date(Open_Date, features = c('month', 'quarter')) %>%
# Extract Season
step_mutate(season = factor(case_when(
between(month(Open_Date), 3, 5) ~ "Spring",
between(month(Open_Date), 6, 8) ~ "Summer",
between(month(Open_Date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
)))  %>%
# Remove Open_Date now that we have better features
step_rm(Open_Date) %>%
# Remove city names because there are new cities in the test data
step_rm(City) %>%
# Integers to factors
step_mutate_at(all_integer_predictors(), fn = factor) %>%
# Ignoring P-variables, turn appropriate variables into factors
step_mutate_at(c('City Group'), fn = factor) %>%
# Dummy factors
step_dummy(all_nominal_predictors()) %>%
# Median imputation for missing quantitative values
step_impute_median(population) %>%
step_impute_median(`per capita annual income`) %>%
step_impute_median(`percentage w higher ed or more`) %>%
# Normalize numeric features
step_normalize(all_numeric_predictors()) %>%
# Remove zero-variance variables
step_zv()%>%
# Remove correlated features
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
# PCR Threshold = .90
step_pca(all_numeric_predictors(), threshold = .85)
# Prep, Bake, and View Recipe
prepped <- prep(rec)
baked <- bake(prepped, full_train) %>%
slice(1:10)
baked
# Set up model
penalized_linear_regression <- linear_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(penalized_linear_regression) %>%
fit(data = full_train) # Fit the workflow
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(penalized_linear_regression) %>%
fit(data = full_train) # Fit the workflow
# Look at fitted LM model
extract_fit_engine(wf) %>%
tidy()
extract_fit_engine(wf) %>%
summary
# Grid of values to tune over
tg <- grid_regular(penalty(),
mixture(),
levels = 5)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
cv_results
View(cv_results)
View(cv_results[[3]][[1]])
# Grid of values to tune over
tg <- grid_regular(penalty(),
mixture(),
levels = 10)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
# Grid of values to tune over
tg <- grid_regular(penalty(),
mixture(),
levels = 20)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
# Find best tuning parameters
plogrpcr_best_tune <- plogrpcr_cv_results %>%
select_best("rmse")
# Find best tuning parameters
best_tune <- cv_results %>%
select_best("rmse")
best_tune
View(cv_results)
View(cv_results[[4]][[1]])
View(cv_results[[3]][[1]])
# Finalize workflow and fit it
final_wf <- wf %>%
finalize_workflow(best_tune) %>%
fit(data = full_train)
extract_fit_engine(final_wf) %>%
tidy()
extract_fit_engine(final_wf) %>%
summary
# Predict Sales for Each ID in full_test
predictions <- bind_cols(full_test$Id,
predict(final_wf, new_data = full_test)) %>% # Bind predictions to corresponding IDs
rename("Id" = "...1", "Prediction" = ".pred")# Rename columns
# Write Predictions to .csv
vroom_write(x=predictions, file="penalized_linear_regression_1_predictions.csv", delim = ",")
# Set up model
random_forest <- rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(random_forest) %>%
fit(data = full_train) # Fit the workflow
# Grid of values to tune over
tg <- grid_regular(penalty(),
mixture(),
levels = 5)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
# Grid of values to tune over
tg <- grid_regular(mtry(),
min_n(),
levels = 5)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Grid of values to tune over
tg <- grid_regular(mtry(),
min_n(),
levels = 5)
baked
# Grid of values to tune over
tg <- grid_regular(mtry(range = c(1, 13)),
min_n(),
levels = 5)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
# Find best tuning parameters
best_tune <- cv_results %>%
select_best("rmse")
# Finalize workflow and fit it
final_wf <- wf %>%
finalize_workflow(best_tune) %>%
fit(data = full_train)
# Finalize workflow and fit it
final_wf <- wf %>%
finalize_workflow(best_tune) %>%
fit(data = full_train)
# Predict Sales for Each ID in full_test
predictions <- bind_cols(full_test$Id,
predict(final_wf, new_data = full_test)) %>% # Bind predictions to corresponding IDs
rename("Id" = "...1", "Prediction" = ".pred")# Rename columns
# Write Predictions to .csv
vroom_write(x=predictions, file="random_forest_1_predictions.csv", delim = ",")
# Set up model
boosted_trees <- boost_tree(trees = 1000,
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("lightgbm") %>%
set_mode("regression")
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(boosted_trees) %>%
fit(data = full_train)
# Set up model
boosted_trees <- boost_tree(trees = 1000,
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("lightgbm") %>%
set_mode("regression")
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(boosted_trees) %>%
fit(data = full_train)
library(bonsai)
library(lightgbm)
# Set up model
boosted_trees <- boost_tree(trees = 1000,
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("lightgbm") %>%
set_mode("regression")
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(boosted_trees) %>%
fit(data = full_train)
# Workflow
wf <- workflow() %>%
add_recipe(rec) %>%
add_model(boosted_trees)
# Grid of values to tune over
tg <- grid_regular(
tree_depth(range = c(1, 5)),
learn_rate(range = c(0, 1), trans=NULL),
levels = 5
)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
best_tune
# Find best tuning parameters
best_tune <- cv_results %>%
select_best("rmse")
best_tune
# Grid of values to tune over
tg <- grid_regular(
tree_depth(range = c(1, 5)),
learn_rate(range = c(0, .25), trans=NULL),
levels = 5
)
# Split data for cross-validation (CV)
folds <- vfold_cv(full_train, v = 5, repeats = 1)
# Run cross-validation
cv_results <- wf %>%
tune_grid(resamples = folds,
grid = tg,
metrics = metric_set(rmse))
# Find best tuning parameters
best_tune <- cv_results %>%
select_best("rmse")
best_tune
# Finalize workflow and fit it
final_wf <- wf %>%
finalize_workflow(best_tune) %>%
fit(data = full_train)
# Predict Sales for Each ID in full_test
predictions <- bind_cols(full_test$Id,
predict(final_wf, new_data = full_test)) %>% # Bind predictions to corresponding IDs
rename("Id" = "...1", "Prediction" = ".pred")# Rename columns
# Write Predictions to .csv
vroom_write(x=predictions, file="boosted_trees_1_predictions.csv", delim = ",")
